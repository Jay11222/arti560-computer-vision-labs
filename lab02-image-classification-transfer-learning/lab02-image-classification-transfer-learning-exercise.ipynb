{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430e7f7b",
   "metadata": {},
   "source": [
    "##### ARTI 560 - Computer Vision  \n",
    "## Image Classification using Transfer Learning - Exercise \n",
    "\n",
    "### Objective\n",
    "\n",
    "In this exercise, you will:\n",
    "\n",
    "1. Select another pretrained model (e.g., VGG16, MobileNetV2, or EfficientNet) and fine-tune it for CIFAR-10 classification.  \n",
    "You'll find the pretrained models in [Tensorflow Keras Applications Module](https://www.tensorflow.org/api_docs/python/tf/keras/applications).\n",
    "\n",
    "2. Before training, inspect the architecture using model.summary() and observe:\n",
    "- Network depth\n",
    "- Number of parameters\n",
    "- Trainable vs Frozen layers\n",
    "\n",
    "3. Then compare its performance with ResNet and the custom CNN.\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- Which model achieved the highest accuracy?\n",
    "- Which model trained faster?\n",
    "- How might the architecture explain the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26d77e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9562fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (50000, 32, 32, 3)\n",
      "Test shape : (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Fix label shape\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "print(\"Train shape:\", x_train.shape)\n",
    "print(\"Test shape :\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ecd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 160\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def build_efficientnet_model(train_backbone=False):\n",
    "    \n",
    "    backbone = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    backbone.trainable = train_backbone  # Frozen\n",
    "    \n",
    "    inputs = keras.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    # Data augmentation\n",
    "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "    x = layers.RandomRotation(0.1)(x)\n",
    "    \n",
    "    # Resize to match EfficientNet input\n",
    "    x = layers.Resizing(IMG_SIZE, IMG_SIZE)(x)\n",
    "    \n",
    "    # Preprocess for EfficientNet\n",
    "    x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "    \n",
    "    # Backbone forward pass\n",
    "    x = backbone(x, training=False)\n",
    "    \n",
    "    # Classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES)(x)  # logits\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=\"EfficientNetB0_CIFAR10\")\n",
    "    \n",
    "    return model, backbone\n",
    "\n",
    "\n",
    "model, backbone = build_efficientnet_model(train_backbone=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8bd8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EfficientNetB0_CIFAR10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EfficientNetB0_CIFAR10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_flip_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_rotation_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resizing_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Resizing</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_flip_1 (\u001b[38;5;33mRandomFlip\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_rotation_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomRotation\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resizing_1 (\u001b[38;5;33mResizing\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m160\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,380,077</span> (16.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,380,077\u001b[0m (16.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">330,506</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m330,506\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Parameter Summary ===\n",
      "Total params       : 4380077\n",
      "Trainable params   : tf.Tensor(330506, shape=(), dtype=int32)\n",
      "Non-trainable params: tf.Tensor(4049571, shape=(), dtype=int32)\n",
      "\n",
      "Backbone layers: 238\n",
      "Backbone trainable: False\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "print(\"\\n=== Parameter Summary ===\")\n",
    "print(\"Total params       :\", model.count_params())\n",
    "print(\"Trainable params   :\", sum(tf.size(w) for w in model.trainable_weights))\n",
    "print(\"Non-trainable params:\", sum(tf.size(w) for w in model.non_trainable_weights))\n",
    "\n",
    "print(\"\\nBackbone layers:\", len(backbone.layers))\n",
    "print(\"Backbone trainable:\", backbone.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc72be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 87ms/step - accuracy: 0.6282 - loss: 1.1006 - val_accuracy: 0.8900 - val_loss: 0.3284 - learning_rate: 3.0000e-04\n",
      "Epoch 2/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 82ms/step - accuracy: 0.7824 - loss: 0.6311 - val_accuracy: 0.9024 - val_loss: 0.2867 - learning_rate: 3.0000e-04\n",
      "Epoch 3/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 84ms/step - accuracy: 0.8004 - loss: 0.5836 - val_accuracy: 0.9020 - val_loss: 0.2755 - learning_rate: 3.0000e-04\n",
      "Epoch 4/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 83ms/step - accuracy: 0.8086 - loss: 0.5613 - val_accuracy: 0.9092 - val_loss: 0.2562 - learning_rate: 3.0000e-04\n",
      "Epoch 5/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 83ms/step - accuracy: 0.8179 - loss: 0.5244 - val_accuracy: 0.9106 - val_loss: 0.2560 - learning_rate: 3.0000e-04\n",
      "Epoch 6/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 83ms/step - accuracy: 0.8253 - loss: 0.5127 - val_accuracy: 0.9102 - val_loss: 0.2503 - learning_rate: 3.0000e-04\n",
      "Epoch 7/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 83ms/step - accuracy: 0.8273 - loss: 0.4964 - val_accuracy: 0.9152 - val_loss: 0.2479 - learning_rate: 3.0000e-04\n",
      "Epoch 8/8\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 83ms/step - accuracy: 0.8308 - loss: 0.4944 - val_accuracy: 0.9160 - val_loss: 0.2410 - learning_rate: 3.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\",\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=8,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad0b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EfficientNetB0 (Frozen) Test Accuracy: 0.9103000164031982\n",
      "EfficientNetB0 (Frozen) Test Loss: 0.26787564158439636\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nEfficientNetB0 (Frozen) Test Accuracy:\", test_acc)\n",
    "print(\"EfficientNetB0 (Frozen) Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "babdebee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone trainable: True\n",
      "Trainable backbone layers: 30 / 238\n",
      "Epoch 1/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 104ms/step - accuracy: 0.7453 - loss: 0.7509 - val_accuracy: 0.8960 - val_loss: 0.3151 - learning_rate: 1.0000e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 98ms/step - accuracy: 0.7980 - loss: 0.5921 - val_accuracy: 0.9026 - val_loss: 0.2829 - learning_rate: 1.0000e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 98ms/step - accuracy: 0.8176 - loss: 0.5333 - val_accuracy: 0.9096 - val_loss: 0.2642 - learning_rate: 1.0000e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 99ms/step - accuracy: 0.8200 - loss: 0.5177 - val_accuracy: 0.9126 - val_loss: 0.2528 - learning_rate: 1.0000e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 98ms/step - accuracy: 0.8304 - loss: 0.4909 - val_accuracy: 0.9158 - val_loss: 0.2467 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "\n",
      "EfficientNetB0 (Fine-tuned) Test Accuracy: 0.9107000231742859\n",
      "EfficientNetB0 (Fine-tuned) Test Loss: 0.26705023646354675\n"
     ]
    }
   ],
   "source": [
    "#  6. Fine-tune EfficientNetB0 (Unfreeze last layers)\n",
    "\n",
    "# Unfreeze backbone\n",
    "backbone.trainable = True\n",
    "\n",
    "# Fine-tune only the last N layers (keep earlier layers frozen)\n",
    "N = 30  # try 20, 30, 50\n",
    "for layer in backbone.layers[:-N]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(\"Backbone trainable:\", backbone.trainable)\n",
    "print(\"Trainable backbone layers:\", sum(l.trainable for l in backbone.layers), \"/\", len(backbone.layers))\n",
    "\n",
    "# IMPORTANT: re-compile after changing trainable flags\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_accuracy\",\n",
    "        factor=0.5,\n",
    "        patience=1,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_ft = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks_ft\n",
    ")\n",
    "\n",
    "#  Evaluate after fine-tuning\n",
    "test_loss_ft, test_acc_ft = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\nEfficientNetB0 (Fine-tuned) Test Accuracy:\", test_acc_ft)\n",
    "print(\"EfficientNetB0 (Fine-tuned) Test Loss:\", test_loss_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f7c0f",
   "metadata": {},
   "source": [
    "### 1. Which model achieved the highest accuracy?\n",
    "\n",
    "The highest accuracy was achieved by **ResNet50V2 (fine-tuned)** with a test accuracy of **91.62%**.\n",
    "\n",
    "Although EfficientNetB0 performed very strongly (91.03% frozen and 91.07% fine-tuned), fine-tuned ResNet50V2 slightly outperformed it.\n",
    "\n",
    "The custom CNN achieved 70.28%, which was significantly lower than both pretrained models.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Which model trained faster?\n",
    "\n",
    "The **custom CNN** trained the fastest because it is smaller and trained from scratch without a large pretrained backbone.\n",
    "\n",
    "Among the transfer learning models:\n",
    "- **EfficientNetB0 (frozen)** trained faster since only the classifier head was updated.\n",
    "- **ResNet50V2 (fine-tuned)** trained the slowest because many deep layers were unfrozen and updated during training.\n",
    "\n",
    "In general, models with more trainable parameters require more computation time.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. How might the architecture explain the differences?\n",
    "\n",
    "The differences in performance can be explained by architectural design:\n",
    "\n",
    "- **Custom CNN** is relatively shallow and lacks pretrained knowledge, so it has limited feature extraction capability compared to large ImageNet-trained models.\n",
    "\n",
    "- **EfficientNetB0** uses compound scaling (balanced depth, width, and resolution), making it highly parameter-efficient. Its pretrained features transferred very well to CIFAR-10, which is why it performed strongly even when frozen.\n",
    "\n",
    "- **ResNet50V2** uses deep residual connections that improve gradient flow and allow effective fine-tuning. When layers were unfrozen, the network adapted better to CIFAR-10, leading to the highest overall accuracy.\n",
    "\n",
    "Overall, transfer learning significantly improved performance, and architectural design influenced how much each model benefited from fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
